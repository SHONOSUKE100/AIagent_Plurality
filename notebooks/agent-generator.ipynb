{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f814df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ikedashou/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from oasis import SocialAgent, AgentGraph\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from oasis import ActionType, LLMAction, ManualAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24070c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4O,\n",
    "    model_config_dict={\"temperature\": 0.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f449631",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_actions = [\n",
    "        ActionType.LIKE_POST,\n",
    "        ActionType.DISLIKE_POST,\n",
    "        ActionType.CREATE_POST,\n",
    "        ActionType.CREATE_COMMENT,\n",
    "        ActionType.LIKE_COMMENT,\n",
    "        ActionType.DISLIKE_COMMENT,\n",
    "        ActionType.SEARCH_POSTS,\n",
    "        ActionType.SEARCH_USER,\n",
    "        ActionType.TREND,\n",
    "        ActionType.REFRESH,\n",
    "        ActionType.DO_NOTHING,\n",
    "        ActionType.FOLLOW,\n",
    "        ActionType.MUTE,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e4c48dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict, field\n",
    "import warnings\n",
    "from camel.prompts import TextPrompt\n",
    "\n",
    "@dataclass\n",
    "class UserInfo:\n",
    "    user_name: str = \"user_name\"\n",
    "    name: str = \"user_name\"\n",
    "    occupation: str = \"学生\"\n",
    "    age: int = 20\n",
    "    hobbies: list = field(default_factory=list)\n",
    "    residence: str = \"東京\"\n",
    "    description: str = \"毎日２キロ走ってます。\"\n",
    "    recsys_type: str = \"twitter\"\n",
    "    is_controllable: bool = False\n",
    "\n",
    "    def to_custom_system_message(self, user_info_template: TextPrompt) -> str:\n",
    "        required_keys = user_info_template.key_words\n",
    "        profile = asdict(self)\n",
    "\n",
    "        info_keys = set(profile.keys())\n",
    "        missing = required_keys - info_keys\n",
    "        extra = info_keys - required_keys\n",
    "\n",
    "        if missing:\n",
    "            raise ValueError(\n",
    "                f\"Missing required keys in UserInfo.profile: {missing}\")\n",
    "        if extra:\n",
    "            warnings.warn(f\"Extra keys not used in UserInfo.profile: {extra}\")\n",
    "\n",
    "        return user_info_template.format(**profile)\n",
    "\n",
    "    def to_system_message(self) -> str:\n",
    "        if self.recsys_type != \"reddit\":\n",
    "            return self.to_twitter_system_message()\n",
    "        else:\n",
    "            return self.to_reddit_system_message()\n",
    "\n",
    "    def to_twitter_system_message(self) -> str:\n",
    "        hobbies_str = \", \".join(self.hobbies)\n",
    "        description = (\n",
    "            f\"You are a {self.age} year old {self.occupation} living in {self.residence}. \"\n",
    "            f\"Your hobbies are {hobbies_str}. \"\n",
    "            f\"{self.description}\"\n",
    "        )\n",
    "\n",
    "        system_content = f\"\"\"\n",
    "# OBJECTIVE\n",
    "You're a Twitter user, and I'll present you with some posts. After you see the posts, choose some actions from the following functions.\n",
    "\n",
    "# SELF-DESCRIPTION\n",
    "Your actions should be consistent with your self-description and personality.\n",
    "{description}\n",
    "\n",
    "# RESPONSE METHOD\n",
    "Please perform actions by tool calling.\n",
    "        \"\"\"\n",
    "\n",
    "        return system_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44aeb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def generate_x_agent_graph(\n",
    "    profile_path,\n",
    "    model,\n",
    "    available_actions\n",
    "):\n",
    "    with open(profile_path, 'r', encoding='utf-8') as f:\n",
    "        agent_info = json.load(f)\n",
    "    agent_graph = AgentGraph()\n",
    "    for agent_id in range(len(agent_info)):\n",
    "        profile = {\n",
    "            \"nodes\": [],\n",
    "            \"edges\": [],\n",
    "            \"other_info\": {},\n",
    "        }\n",
    "        \n",
    "        profile[\"other_info\"][\"user_profile\"] = agent_info[agent_id]\n",
    "\n",
    "        user_info = UserInfo(\n",
    "            user_name = agent_info[agent_id][\"user_name\"],\n",
    "            name = agent_info[agent_id][\"name\"],\n",
    "            occupation = agent_info[agent_id][\"occupation\"],\n",
    "            age = agent_info[agent_id][\"age\"],\n",
    "            hobbies = agent_info[agent_id][\"hobbies\"],\n",
    "            residence = agent_info[agent_id][\"residence\"],\n",
    "            description = agent_info[agent_id][\"description\"],\n",
    "            recsys_type = \"twitter\"\n",
    "        )\n",
    "\n",
    "        agent = SocialAgent(\n",
    "            agent_id=agent_id,\n",
    "            user_info=user_info,\n",
    "            model=model,\n",
    "            agent_graph=agent_graph,\n",
    "            available_actions=available_actions,\n",
    "        )\n",
    "\n",
    "        agent_graph.add_agent(agent)\n",
    "    \n",
    "    return agent_graph\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92c6fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_graph = generate_x_agent_graph(\n",
    "    profile_path=\"../data/persona/persona.json\",\n",
    "    model=model,\n",
    "    available_actions=available_actions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c78b4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_path ../data/twitter_simulation.db\n",
      "2025-11-22 10:44:13,293 - social.twitter - INFO - Starting to refresh recommendation system cache...\n",
      "2025-11-22 10:44:13,296 - social.twitter - ERROR - list index out of range\n",
      "2025-11-22 10:44:13,296 - oasis.env - INFO - update rec table.\n",
      "2025-11-22 10:44:13,414 - social.agent - INFO - Agent 0: {'success': True, 'post_id': 1}\n",
      "2025-11-22 10:44:13,432 - social.agent - INFO - Agent 0: {'success': True, 'comment_id': 1}\n",
      "2025-11-22 10:44:13,447 - social.agent - INFO - Agent 1: {'success': True, 'comment_id': 2}\n",
      "2025-11-22 10:44:13,448 - oasis.env - INFO - performed all actions.\n",
      "2025-11-22 10:44:13,449 - social.twitter - INFO - Starting to refresh recommendation system cache...\n",
      "2025-11-22 10:50:36,324 - social.twitter - ERROR - Failed to load the model: Twitter/twhin-bert-base\n",
      "2025-11-22 10:50:36,330 - oasis.env - INFO - update rec table.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cancellation requested; stopping current tasks.\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     38\u001b[39m actions_2 = {\n\u001b[32m     39\u001b[39m     agent: LLMAction()\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, agent \u001b[38;5;129;01min\u001b[39;00m env.agent_graph.get_agents()\n\u001b[32m     41\u001b[39m }\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Perform the actions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m env.step(actions_2)\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Close the environment\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m env.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/environment/env.py:193\u001b[39m, in \u001b[36mOasisEnv.step\u001b[39m\u001b[34m(self, actions)\u001b[39m\n\u001b[32m    190\u001b[39m             tasks.append(\u001b[38;5;28mself\u001b[39m._perform_llm_action(agent))\n\u001b[32m    192\u001b[39m \u001b[38;5;66;03m# Execute all tasks concurrently\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m    194\u001b[39m env_log.info(\u001b[33m\"\u001b[39m\u001b[33mperformed all actions.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# # Control some agents to perform actions\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Update the clock\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/environment/env.py:128\u001b[39m, in \u001b[36mOasisEnv._perform_llm_action\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Send the request to the llm model and execute the action.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.llm_semaphore:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m agent.perform_action_by_llm()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_agent/agent.py:125\u001b[39m, in \u001b[36mSocialAgent.perform_action_by_llm\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mperform_action_by_llm\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    124\u001b[39m     \u001b[38;5;66;03m# Get posts:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     env_prompt = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.to_text_prompt()\n\u001b[32m    126\u001b[39m     user_msg = BaseMessage.make_user_message(\n\u001b[32m    127\u001b[39m         role_name=\u001b[33m\"\u001b[39m\u001b[33mUser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    128\u001b[39m         content=(\n\u001b[32m   (...)\u001b[39m\u001b[32m    131\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mactions for example to just like the posts. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHere is your social media environment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m))\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_agent/agent_environment.py:99\u001b[39m, in \u001b[36mSocialEnvironment.to_text_prompt\u001b[39m\u001b[34m(self, include_posts, include_followers, include_follows)\u001b[39m\n\u001b[32m     95\u001b[39m followers_env = (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_followers_env()\n\u001b[32m     96\u001b[39m                  \u001b[38;5;28;01mif\u001b[39;00m include_follows \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo followers.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m follows_env = (\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_follows_env()\n\u001b[32m     98\u001b[39m                \u001b[38;5;28;01mif\u001b[39;00m include_followers \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo follows.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m posts_env = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_posts_env() \u001b[38;5;28;01mif\u001b[39;00m include_posts \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env_template.substitute(\n\u001b[32m    102\u001b[39m     followers_env=followers_env,\n\u001b[32m    103\u001b[39m     follows_env=follows_env,\n\u001b[32m    104\u001b[39m     posts_env=posts_env,\n\u001b[32m    105\u001b[39m     groups_env=\u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_group_env(),\n\u001b[32m    106\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_agent/agent_environment.py:57\u001b[39m, in \u001b[36mSocialEnvironment.get_posts_env\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_posts_env\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     posts = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.action.refresh()\n\u001b[32m     58\u001b[39m     \u001b[38;5;66;03m# TODO: Replace posts json format string to other formats\u001b[39;00m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m posts[\u001b[33m\"\u001b[39m\u001b[33msuccess\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_agent/agent_action.py:132\u001b[39m, in \u001b[36mSocialAction.refresh\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrefresh\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     97\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Refresh to get recommended posts.\u001b[39;00m\n\u001b[32m     98\u001b[39m \n\u001b[32m     99\u001b[39m \u001b[33;03m    This method invokes an asynchronous action to refresh and fetch\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    130\u001b[39m \u001b[33;03m        }\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.perform_action(\u001b[38;5;28;01mNone\u001b[39;00m, ActionType.REFRESH.value)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_agent/agent_action.py:65\u001b[39m, in \u001b[36mSocialAction.perform_action\u001b[39m\u001b[34m(self, message, type)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mperform_action\u001b[39m(\u001b[38;5;28mself\u001b[39m, message: Any, \u001b[38;5;28mtype\u001b[39m: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     63\u001b[39m     message_id = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.channel.write_to_receive_queue(\n\u001b[32m     64\u001b[39m         (\u001b[38;5;28mself\u001b[39m.agent_id, message, \u001b[38;5;28mtype\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.channel.read_from_send_queue(message_id)\n\u001b[32m     66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[32m2\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/HUMAI/AIagent_Plurality/.venv/lib/python3.12/site-packages/oasis/social_platform/channel.py:70\u001b[39m, in \u001b[36mChannel.read_from_send_queue\u001b[39m\u001b[34m(self, message_id)\u001b[39m\n\u001b[32m     68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m message  \u001b[38;5;66;03m# Return the found message\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Temporarily suspend to avoid tight looping\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\n\u001b[32m     71\u001b[39m     \u001b[32m0.1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.10-macos-aarch64-none/lib/python3.12/asyncio/tasks.py:665\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    661\u001b[39m h = loop.call_later(delay,\n\u001b[32m    662\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    663\u001b[39m                     future, result)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    667\u001b[39m     h.cancel()\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import oasis\n",
    "# Define the path to the database\n",
    "db_path = \"../data/twitter_simulation.db\"\n",
    "\n",
    "# Delete the old database\n",
    "if os.path.exists(db_path):\n",
    "    os.remove(db_path)\n",
    "\n",
    "# Make the environment\n",
    "env = oasis.make(\n",
    "    agent_graph=agent_graph,\n",
    "    platform=oasis.DefaultPlatformType.TWITTER,\n",
    "    database_path=db_path,\n",
    ")\n",
    "\n",
    "# Run the environment\n",
    "await env.reset()\n",
    "\n",
    "actions_1 = {}\n",
    "actions_1[env.agent_graph.get_agent(0)] = [\n",
    "    ManualAction(action_type=ActionType.CREATE_POST,\n",
    "                    action_args={\"content\": \"Hello, world!\"}),\n",
    "    ManualAction(action_type=ActionType.CREATE_COMMENT,\n",
    "                    action_args={\n",
    "                        \"post_id\": \"1\",\n",
    "                        \"content\": \"Welcome to the OASIS World!\"\n",
    "                    })\n",
    "]\n",
    "actions_1[env.agent_graph.get_agent(1)] = ManualAction(\n",
    "    action_type=ActionType.CREATE_COMMENT,\n",
    "    action_args={\n",
    "        \"post_id\": \"1\",\n",
    "        \"content\": \"I like the OASIS world.\"\n",
    "    })\n",
    "await env.step(actions_1)\n",
    "\n",
    "actions_2 = {\n",
    "    agent: LLMAction()\n",
    "    for _, agent in env.agent_graph.get_agents()\n",
    "}\n",
    "\n",
    "# Perform the actions\n",
    "await env.step(actions_2)\n",
    "\n",
    "# Close the environment\n",
    "await env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1300a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6796f221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
